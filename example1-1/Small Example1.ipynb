{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40bc013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/makayla/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!pip install crosslingual-coreference\n",
    "#!python -m ipykernel install --user --name spacey_pipeline2\n",
    "import spacy\n",
    "import crosslingual_coreference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b03ab51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'head': 'Jennifer Anne Doudna', 'type': 'date of birth', 'tail': 'February 19, 1964'}, {'head': 'Jennifer Anne Doudna', 'type': 'award received', 'tail': 'Nobel Prize in Chemistry'}, {'head': 'Emmanuelle Charpentier', 'type': 'award received', 'tail': 'Nobel Prize in Chemistry'}]\n"
     ]
    }
   ],
   "source": [
    "def extract_triplets(text):\n",
    "    triplets = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "    return triplets\n",
    "sent = '<s><triplet> Jennifer Anne Doudna <subj> February 19, 1964 <obj> date of birth <subj> Nobel Prize in Chemistry <obj> award received <triplet> Emmanuelle Charpentier <subj> Nobel Prize in Chemistry <obj> award received</s>'\n",
    "print(extract_triplets(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a23f089",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<class '__main__.RebelComponent'> is a built-in class",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid-less\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129;43m@Language\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrebel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequires\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdoc.sents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43massigns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdoc._.rel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBabelscape/rebel-large\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mRebelComponent\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnlp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01massert\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "File \u001b[0;32m~/Documents/cal-poly-classes/dist-systs/csc369-mind-over-matter/spacey_pipeline/lib/python3.9/site-packages/spacy/language.py:482\u001b[0m, in \u001b[0;36mLanguage.factory.<locals>.add_factory\u001b[0;34m(factory_func)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m internal_name \u001b[38;5;129;01min\u001b[39;00m registry\u001b[38;5;241m.\u001b[39mfactories:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# We only check for the internal name here â€“ it's okay if it's a\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;66;03m# subclass and the base class has a factory of the same name. We\u001b[39;00m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;66;03m# also only raise if the function is different to prevent raising\u001b[39;00m\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;66;03m# if module is reloaded.\u001b[39;00m\n\u001b[1;32m    481\u001b[0m     existing_func \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mfactories\u001b[38;5;241m.\u001b[39mget(internal_name)\n\u001b[0;32m--> 482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_same_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactory_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexisting_func\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    483\u001b[0m         err \u001b[38;5;241m=\u001b[39m Errors\u001b[38;5;241m.\u001b[39mE004\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    484\u001b[0m             name\u001b[38;5;241m=\u001b[39mname, func\u001b[38;5;241m=\u001b[39mexisting_func, new_func\u001b[38;5;241m=\u001b[39mfactory_func\n\u001b[1;32m    485\u001b[0m         )\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n",
      "File \u001b[0;32m~/Documents/cal-poly-classes/dist-systs/csc369-mind-over-matter/spacey_pipeline/lib/python3.9/site-packages/spacy/util.py:1065\u001b[0m, in \u001b[0;36mis_same_func\u001b[0;34m(func1, func2)\u001b[0m\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m same_name \u001b[38;5;241m=\u001b[39m func1\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m==\u001b[39m func2\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m same_file \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetfile(func2)\n\u001b[1;32m   1066\u001b[0m same_code \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetsourcelines(func1) \u001b[38;5;241m==\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetsourcelines(func2)\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m same_name \u001b[38;5;129;01mand\u001b[39;00m same_file \u001b[38;5;129;01mand\u001b[39;00m same_code\n",
      "File \u001b[0;32m~/Documents/cal-poly-classes/dist-systs/csc369-mind-over-matter/spacey_pipeline/lib/python3.9/site-packages/torch/package/package_importer.py:620\u001b[0m, in \u001b[0;36mpatched_getfile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _package_imported_modules:\n\u001b[1;32m    619\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _package_imported_modules[\u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_orig_getfile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.9/inspect.py:666\u001b[0m, in \u001b[0;36mgetfile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    665\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is a built-in class\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mobject\u001b[39m))\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismethod(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28mobject\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: <class '__main__.RebelComponent'> is a built-in class"
     ]
    }
   ],
   "source": [
    "# Add rebel component https://github.com/Babelscape/rebel/blob/main/spacy_component.py\n",
    "import requests\n",
    "import re\n",
    "import hashlib\n",
    "from spacy import Language\n",
    "from typing import List\n",
    "\n",
    "from spacy.tokens import Doc, Span\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "def call_wiki_api(item):\n",
    "  try:\n",
    "    url = f\"https://www.wikidata.org/w/api.php?action=wbsearchentities&search={item}&language=en&format=json\"\n",
    "    data = requests.get(url).json()\n",
    "    # Return the first id (Could upgrade this in the future)\n",
    "    return data['search'][0]['id']\n",
    "  except:\n",
    "    return 'id-less'\n",
    "\n",
    "\n",
    "@Language.factory(\n",
    "    \"rebel\",\n",
    "    requires=[\"doc.sents\"],\n",
    "    assigns=[\"doc._.rel\"],\n",
    "    default_config={\n",
    "        \"model_name\": \"Babelscape/rebel-large\",\n",
    "        \"device\": -1,\n",
    "    },\n",
    ")\n",
    "class RebelComponent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        nlp,\n",
    "        name,\n",
    "        model_name: str,\n",
    "        device: int,\n",
    "    ):\n",
    "        assert model_name is not None, \"\"\n",
    "        self.triplet_extractor = pipeline(\"text2text-generation\", model=model_name, tokenizer=model_name, device=device)\n",
    "        self.entity_mapping = {}\n",
    "        # Register custom extension on the Doc\n",
    "        if not Doc.has_extension(\"rel\"):\n",
    "          Doc.set_extension(\"rel\", default={})\n",
    "\n",
    "    def get_wiki_id(self, item: str):\n",
    "        mapping = self.entity_mapping.get(item)\n",
    "        if mapping:\n",
    "          return mapping\n",
    "        else:\n",
    "          res = call_wiki_api(item)\n",
    "          self.entity_mapping[item] = res\n",
    "          return res\n",
    "\n",
    "    \n",
    "    def _generate_triplets(self, sent: Span) -> List[dict]:\n",
    "        output_ids = self.triplet_extractor(sent.text, return_tensors=True, return_text=False)[0][\"generated_token_ids\"][\"output_ids\"]\n",
    "        extracted_text = self.triplet_extractor.tokenizer.batch_decode(output_ids[0])\n",
    "        extracted_triplets = extract_triplets(extracted_text[0])\n",
    "        return extracted_triplets\n",
    "\n",
    "    def set_annotations(self, doc: Doc, triplets: List[dict]):\n",
    "        for triplet in triplets:\n",
    "            # Remove self-loops (relationships that start and end at the entity)\n",
    "            if triplet['head'] == triplet['tail']:\n",
    "                continue\n",
    "\n",
    "            # Use regex to search for entities\n",
    "            head_span = re.search(triplet[\"head\"], doc.text)\n",
    "            tail_span = re.search(triplet[\"tail\"], doc.text)\n",
    "\n",
    "            # Skip the relation if both head and tail entities are not present in the text\n",
    "            # Sometimes the Rebel model hallucinates some entities\n",
    "            if not head_span or not tail_span:\n",
    "                continue\n",
    "\n",
    "            index = hashlib.sha1(\"\".join([triplet['head'], triplet['tail'], triplet['type']]).encode('utf-8')).hexdigest()\n",
    "            if index not in doc._.rel:\n",
    "                # Get wiki ids and store results\n",
    "                doc._.rel[index] = {\"relation\": triplet[\"type\"], \"head_span\": {'text': triplet['head'], 'id': self.get_wiki_id(triplet['head'])}, \"tail_span\": {'text': triplet['tail'], 'id': self.get_wiki_id(triplet['tail'])}}\n",
    "\n",
    "    def __call__(self, doc: Doc) -> Doc:\n",
    "        for sent in doc.sents:\n",
    "            sentence_triplets = self._generate_triplets(sent)\n",
    "            self.set_annotations(doc, sentence_triplets)\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd036c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "models/crosslingual-coreference/minilm/model.tar.gz:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 264005/358489 [00:16<00:05, 17162.14KB/s]"
     ]
    }
   ],
   "source": [
    "DEVICE = -1 # Number of the GPU, -1 if want to use CPU\n",
    "\n",
    "# Add coreference resolution model\n",
    "coref = spacy.load('en_core_web_sm', disable=['ner', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer'])\n",
    "coref.add_pipe(\n",
    "    \"xx_coref\", config={\"chunk_size\": 2500, \"chunk_overlap\": 2, \"device\": DEVICE})\n",
    "\n",
    "# Define rel extraction model\n",
    "\n",
    "rel_ext = spacy.load('en_core_web_sm', disable=['ner', 'lemmatizer', 'attribute_rules', 'tagger'])\n",
    "rel_ext.add_pipe(\"rebel\", config={\n",
    "    'device':DEVICE, # Number of the GPU, -1 if want to use CPU\n",
    "    'model_name':'Babelscape/rebel-large'} # Model used, will default to 'Babelscape/rebel-large' if not given\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c174a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_text = \"Christian Drosten works in Germany. He likes to work for Google.\"\n",
    "\n",
    "coref_text = coref(input_text)._.resolved_text\n",
    "\n",
    "doc = rel_ext(coref_text)\n",
    "\n",
    "for value, rel_dict in doc._.rel.items():\n",
    "    print(f\"{value}: {rel_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wikipedia\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Define Neo4j connection\n",
    "host = 'bolt://127.0.0.1:7687'\n",
    "user = 'neo4j'\n",
    "password = '12345678'\n",
    "driver = GraphDatabase.driver(host,auth=(user, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb0b2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<neo4j.api.ServerInfo at 0x7f46043e46a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.get_server_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f88283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_query = \"\"\"\n",
    "UNWIND $data AS row\n",
    "MERGE (h:Entity {id: CASE WHEN NOT row.head_span.id = 'id-less' THEN row.head_span.id ELSE row.head_span.text END})\n",
    "ON CREATE SET h.text = row.head_span.text\n",
    "MERGE (t:Entity {id: CASE WHEN NOT row.tail_span.id = 'id-less' THEN row.tail_span.id ELSE row.tail_span.text END})\n",
    "ON CREATE SET t.text = row.tail_span.text\n",
    "WITH row, h, t\n",
    "CALL apoc.merge.relationship(h, toUpper(replace(row.relation,' ', '_')),\n",
    "  {file_id: row.file_id},\n",
    "  {},\n",
    "  t,\n",
    "  {}\n",
    ")\n",
    "YIELD rel\n",
    "RETURN distinct 'done' AS result;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_query(query, params={}):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query, params)\n",
    "        return pd.DataFrame([r.values() for r in result], columns=result.keys())\n",
    "\n",
    "import json\n",
    "def store_content(file):\n",
    "    #try:\n",
    "    file_id = file.split(\"/\")[-1].split(\".\")[0]\n",
    "    f = open(file)\n",
    "    doc = json.load(f)\n",
    "    input_text = doc[\"text\"]\n",
    "    print(input_text[:100])\n",
    "    coref_text = coref(input_text)._.resolved_text\n",
    "    doc = rel_ext(coref_text)\n",
    "    params = [rel_dict for value, rel_dict in doc._.rel.items()]\n",
    "    for p in params:\n",
    "        p['file_id']=file_id\n",
    "    run_query(import_query, {'data': params})\n",
    "    #except Exception as e:\n",
    "    #  print(f\"Couldn't parse text for {page} due to {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e54805f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['domains/d5.txt.json',\n",
       " 'domains/d6.txt.json',\n",
       " 'domains/d1.txt.json',\n",
       " 'domains/d2.txt.json',\n",
       " 'domains/d4.txt.json',\n",
       " 'domains/d3.txt.json']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "DIR=\"domains\"\n",
    "files = glob.glob(DIR + '/*.json')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f01c91b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing domains/d5.txt.json\n",
      "Familial Attributes\n",
      "\n",
      "Genetic and environmental conditions shared in families may contribute to the d\n",
      "Parsing domains/d6.txt.json\n",
      "Central Schema Attributes\n",
      "\n",
      "Many factors determine how pain signals from the periphery are transforme\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/myuser/spacey_pipeline3/lib/python3.9/site-packages/allennlp/modules/token_embedders/pretrained_transformer_embedder.py:385: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  num_effective_segments = (seq_lengths + self._max_length - 1) // self._max_length\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    print(f\"Parsing {file}\")\n",
    "    store_content(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cab1a517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batches</th>\n",
       "      <th>total</th>\n",
       "      <th>timeTaken</th>\n",
       "      <th>committedOperations</th>\n",
       "      <th>failedOperations</th>\n",
       "      <th>failedBatches</th>\n",
       "      <th>retries</th>\n",
       "      <th>errorMessages</th>\n",
       "      <th>batch</th>\n",
       "      <th>operations</th>\n",
       "      <th>wasTerminated</th>\n",
       "      <th>failedParams</th>\n",
       "      <th>updateStatistics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>35</td>\n",
       "      <td>196</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>{'Cannot merge the following node because of n...</td>\n",
       "      <td>{'total': 243, 'committed': 196, 'failed': 47,...</td>\n",
       "      <td>{'total': 243, 'committed': 196, 'failed': 47,...</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'nodesDeleted': 0, 'labelsAdded': 114, 'relat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batches  total  timeTaken  committedOperations  failedOperations  \\\n",
       "0      243    243         35                  196                47   \n",
       "\n",
       "   failedBatches  retries                                      errorMessages  \\\n",
       "0             47        0  {'Cannot merge the following node because of n...   \n",
       "\n",
       "                                               batch  \\\n",
       "0  {'total': 243, 'committed': 196, 'failed': 47,...   \n",
       "\n",
       "                                          operations  wasTerminated  \\\n",
       "0  {'total': 243, 'committed': 196, 'failed': 47,...          False   \n",
       "\n",
       "  failedParams                                   updateStatistics  \n",
       "0           {}  {'nodesDeleted': 0, 'labelsAdded': 114, 'relat...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_query(\"\"\"\n",
    "CALL apoc.periodic.iterate(\"\n",
    "  MATCH (e:Entity)\n",
    "  WHERE e.id STARTS WITH 'Q'\n",
    "  RETURN e\n",
    "\",\"\n",
    "  // Prepare a SparQL query\n",
    "  WITH 'SELECT * WHERE{ ?item rdfs:label ?name . filter (?item = wd:' + e.id + ') filter (lang(?name) = \\\\\"en\\\\\") ' +\n",
    "     'OPTIONAL {?item wdt:P31 [rdfs:label ?label] .filter(lang(?label)=\\\\\"en\\\\\")}}' AS sparql, e\n",
    "  // make a request to Wikidata\n",
    "  CALL apoc.load.jsonParams(\n",
    "    'https://query.wikidata.org/sparql?query=' + \n",
    "      + apoc.text.urlencode(sparql),\n",
    "      { Accept: 'application/sparql-results+json'}, null)\n",
    "  YIELD value\n",
    "  UNWIND value['results']['bindings'] as row\n",
    "  SET e.wikipedia_name = row.name.value\n",
    "  WITH e, row.label.value AS label\n",
    "  MERGE (c:Class {id:label})\n",
    "  MERGE (e)-[:INSTANCE_OF]->(c)\n",
    "  RETURN distinct 'done'\", {batchSize:1, retry:1})\n",
    "\"\"\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e57c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723260f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
